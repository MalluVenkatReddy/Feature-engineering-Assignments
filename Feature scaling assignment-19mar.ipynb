{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea14b20-d243-48cf-96f3-d6729f3ca4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its \n",
    "application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8610d-16df-41c0-b4ee-f357e1f33971",
   "metadata": {},
   "source": [
    "#### minimum of feature is made equal to zero and the maximum of feature equal to one. MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b1d238-8d49-4113-ac2f-93d382857c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04359673, 0.04026846, 0.06475904],\n",
       "       [0.02152589, 0.02684564, 0.        ],\n",
       "       [0.0373297 , 0.04362416, 0.07108434],\n",
       "       ...,\n",
       "       [0.11280654, 0.10067114, 0.        ],\n",
       "       [0.03051771, 0.03355705, 0.        ],\n",
       "       [0.10490463, 0.09395973, 0.10120482]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df_taxi=sns.load_dataset('taxis')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar_norm=MinMaxScaler()\n",
    "scalar_norm.fit_transform(df_taxi[['distance','fare','tip']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247db948-2812-48a3-998c-6b9c9ee475a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? \n",
    "Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc01da8-276c-47f4-860c-ee5dc79d454d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Normalization is the process of scaling individual samples to have unit norm. The most interesting part is that unlike the other scalers which work on the individual column values, the Normalizer works on the rows! Each row of the dataframe with at least one non-zero component is rescaled independently of other samples so that its norm (l1, l2, or inf) equals one.\n",
    "\n",
    "Just like MinMax Scaler, the Normalizer also converts the values between 0 and 1, and between -1 to 1 when there are negative values in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0df2b0-9ec8-45ef-84d0-eaf6d820aad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213461</td>\n",
       "      <td>0.933894</td>\n",
       "      <td>0.286839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156064</td>\n",
       "      <td>0.987747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>0.295702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267899</td>\n",
       "      <td>0.939386</td>\n",
       "      <td>0.213971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231742</td>\n",
       "      <td>0.965592</td>\n",
       "      <td>0.118017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>0.160133</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.226322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>0.307453</td>\n",
       "      <td>0.951563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.968117</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.983020</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.242956</td>\n",
       "      <td>0.946580</td>\n",
       "      <td>0.212034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     0.213461  0.933894  0.286839\n",
       "1     0.156064  0.987747  0.000000\n",
       "2     0.171657  0.939731  0.295702\n",
       "3     0.267899  0.939386  0.213971\n",
       "4     0.231742  0.965592  0.118017\n",
       "...        ...       ...       ...\n",
       "6428  0.160133  0.960800  0.226322\n",
       "6429  0.307453  0.951563  0.000000\n",
       "6430  0.250500  0.968117  0.000000\n",
       "6431  0.183497  0.983020  0.000000\n",
       "6432  0.242956  0.946580  0.212034\n",
       "\n",
       "[6433 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "df_taxi=sns.load_dataset('taxis')\n",
    "df=pd.DataFrame(normalize(df_taxi[['distance','fare','tip']]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286d5c3-34dd-4ce2-bbf6-02c2cca46b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an \n",
    "example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b79c6-8ab2-4d9e-b431-90888eed946a",
   "metadata": {},
   "source": [
    "#### PCA helps us to identify patterns in data based on the correlation between features. In a nutshell, PCA aims to find the directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions than the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6141d9-e190-4d8b-988c-cee4959e5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature \n",
    "Extraction? Provide an example to illustrate this concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a2d07-0def-4dcc-9bd7-001dd527b3c1",
   "metadata": {},
   "source": [
    "#### By discarding minor components, the PCA effectively reduces the number of features and displays the data set in a low- dimensional subspace. In this study the feature extraction algorithm based on PCA is chosen. The coefficients of these methods are used as feature vectors which efficiently represent iris signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973f0ee-eee9-4d2c-b3c5-99e7d7f73a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset \n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to \n",
    "preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3063cc0e-507c-4c1c-995d-0a0e8c17befd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>deliverytime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  rating  deliverytime\n",
       "0     10      20            30\n",
       "1      2       4             3\n",
       "2     30      15            44"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df=pd.DataFrame([[10,20,30],[2,4,3],[30,15,44]],columns=['price','rating','deliverytime'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a94728e-c188-4404-b4a0-85071ba1d2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28571429, 1.        , 0.65853659],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.6875    , 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar_norm=MinMaxScaler()\n",
    "scalar_norm.fit_transform(df[['price','rating','deliverytime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0b5cb-6214-4e29-ac71-a5e148394e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many \n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the \n",
    "dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f2711-faa8-47ab-aa5c-3db9f620fe75",
   "metadata": {},
   "source": [
    "#### PCA is not yet covered, will attempt this question after PCA Algorithm covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3d1ce-706c-4246-8481-3dae14049d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the \n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f57e94aa-28ef-49f6-acf2-242a38d5e774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_taxi=pd.DataFrame([1, 5, 10, 15, 20],columns=['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76f869c-859d-400e-93de-c6df39869ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.21052632],\n",
       "       [0.47368421],\n",
       "       [0.73684211],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar_norm=MinMaxScaler()\n",
    "scalar_norm.fit_transform(df_taxi[['values']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662e1d8-6aa6-4a4a-834e-effdeb0f01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform \n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e42071b-07f8-40e9-80a3-714e3186fd8a",
   "metadata": {},
   "source": [
    "### PCA is not yet covered, will attempt this question after PCA Algorithm covered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
